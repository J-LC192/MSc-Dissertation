{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec Sentiment Analysis\n",
    "\n",
    "## Section 1: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import MaxAbsScaler \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from joblib import dump\n",
    "import os\n",
    "from joblib import load\n",
    "import gensim\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "# Edit the font, font size, and axes width\n",
    "mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [8.0, 8.0]\n",
    "mpl.rcParams['figure.dpi'] = 120\n",
    "mpl.rcParams['savefig.dpi'] = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Semeval data\n",
    "df_semeval = pd.read_json(\"../01_Data/05_Semeval/Headline_Trainingdata.json\")\n",
    "df_semeval_val = pd.read_json(\"../01_Data/05_Semeval/Headline_Trialdata.json\")\n",
    "#df_semeval_test = pd.read_json(\"../01_Data/05_Semeval/Headline_Testdata.json\")\n",
    "df_semeval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train: {df_semeval.shape},val: {df_semeval_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append validation to semeval training data\n",
    "df_semeval=df_semeval.append(df_semeval_val)\n",
    "print(f\"train: {df_semeval.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semeval[\"Sentiment_cat\"]=[\"positive\" if x>0 else \"negative\" for x in df_semeval[\"sentiment\"]]\n",
    "df_semeval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semeval[\"Sentiment_cat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the rise and Fall dataset\n",
    "df_RiseFall =pd.read_excel(\"../01_Data/06_Rise_Fall_News/1_News_Fullset_Risefall.xlsx\",index_col=0)\n",
    "\n",
    "df_RiseFall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many records are positive and negative\n",
    "df_RiseFall[\"target_sentiment\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Train - Test set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the enlarged dataset \n",
    "docs_train, docs_test, y_train, y_test = train_test_split(df_semeval.title, df_semeval[\"Sentiment_cat\"], \n",
    "                                                          test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create copies later used for entity recognition\n",
    "docs_train_orig = docs_train.copy()\n",
    "docs_test_orig = docs_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# uncomment to use Rise and Fall News sample \n",
    "docs_train, docs_test, y_train, y_test = train_test_split(df_RiseFall.Title, df_RiseFall.target_sentiment, \n",
    "                                                          test_size=0.2, random_state=7)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement stratified sampling !?\n",
    "\"\"\"from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "stratified_splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=7)\n",
    "\n",
    "train_index, test_index = list(stratified_splitter.split(df_RiseFall, df_RiseFall[\"target_sentiment\"]))[0]\n",
    "trainset = df.loc[train_index]\n",
    "testset = df.loc[test_index]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"instances: train: {len(docs_train)}; test: {len(docs_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Data transformation\n",
    "\n",
    "### Section 3.1:Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "# only tokenize without lower casing\n",
    "docs_train = [nltk.word_tokenize(line)for line in docs_train.values]\n",
    "print(docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform test data\n",
    "docs_test = [nltk.word_tokenize(line) for line in docs_test.values]\n",
    "docs_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from gensim.utils import simple_preprocess\n",
    "\n",
    "# Tokenize the title of each articles, including lower casing\n",
    "docs_train = [simple_preprocess(line, deacc=True) for line in docs_train.values]\n",
    "print(docs_train)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without lower casing results in better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# transform test data\n",
    "docs_test = [simple_preprocess(line, deacc=True) for line in docs_test.values]\n",
    "docs_test\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.2: Preprocessing\n",
    "Removal of special characters, numbers, Stop-words etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/\n",
    "# https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocessor (token):\n",
    "  \n",
    "    # remove special characters (matches all characters not specified)\n",
    "    #pattern = r'[^a-zA-z0-9\\s]'\n",
    "    pattern = r'[^a-zA-z0-9]'\n",
    "    text = re.sub(pattern, '', token)\n",
    "    \n",
    "    # remove numbers\n",
    "    if bool(re.search(r'\\d', text)):\n",
    "        text = re.sub('[0-9]{5,}', '#####', text)\n",
    "        text = re.sub('[0-9]{4}', '####', text)\n",
    "        text = re.sub('[0-9]{3}', '###', text)\n",
    "        text = re.sub('[0-9]{2}', '##', text)\n",
    "        text = re.sub('[0-9]{1}', '#', text)\n",
    "        \n",
    "    # remove missspelling (unlikely in newswires, so no) \n",
    "    \n",
    "    # removing contractions (maybe ?)\n",
    "    \n",
    "    # remove stop words\n",
    "    #stopWords = set(stopwords.words('english'))\n",
    "    stopWords = [\"to\",\"of\",\"and\",\"a\"]\n",
    "    \n",
    "    if text in stopWords:\n",
    "        text=''\n",
    "           \n",
    "    return text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK Stopwords removal reduces accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# apply preprocessor\n",
    "docs_train = [[preprocessor(word) for word in tokens] for tokens in docs_train]\n",
    "\n",
    "# drop empty strings\n",
    "docs_train = [[(word) for word in tokens if word] for tokens in docs_train]\n",
    "print(docs_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprocessing to test data\n",
    "docs_test = [[preprocessor(word) for word in tokens] for tokens in docs_test]\n",
    "\n",
    "# drop empty strings\n",
    "docs_test = [[(word) for word in tokens if word] for tokens in docs_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.3: Entity recognition and removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy\n",
    "#nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# remove entities\n",
    "\n",
    "train_entitites=[]\n",
    "\n",
    "# loop through train documents and create nlp objects\n",
    "for sentence in docs_train_orig:\n",
    "    sen = nlp(sentence)\n",
    "    \n",
    "    # create list of entity strings\n",
    "    train_entitites.append([word.text for word in sen.ents])\n",
    "\n",
    "# flatten entity list of lists\n",
    "flat_train_entities = [item for sublist in train_entitites for item in sublist]\n",
    "    \n",
    "#print(flat_train_entities[:10])\n",
    "\n",
    "# filter out entities\n",
    "docs_train = [[word if word not in flat_train_entities else '' for word in sentences] for sentences in docs_train]\n",
    "docs_train[:2]  \n",
    "\n",
    "# drop empty strings\n",
    "docs_train = [[(word) for word in tokens if word] for tokens in docs_train]\n",
    "print(docs_train[:3])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only marginally improves accurarcy and is computationally very expensive to process on real data.\n",
    "Thus, named entity recognition is not included in the final implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# loop through train documents and create nlp objects\n",
    "for sentence in docs_train[:3]:\n",
    "    sen = nlp(sentence)\n",
    "    \n",
    "    # create list of entity strings\n",
    "    entitites = [word.text for word in sen.ents]\n",
    "    \n",
    "    print(entitites)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Tag each token\n",
    "docs_train2 = [nltk.pos_tag(word)for word in docs_train]\n",
    "docs_train2[0:5]\n",
    "\n",
    "#nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "docs_train3 = [nltk.chunk.ne_chunk(sentence) for sentence in docs_train2]\n",
    "docs_train3\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# apply for test\n",
    "\n",
    "# remove entities\n",
    "\n",
    "test_entitites=[]\n",
    "\n",
    "# loop through train documents and create nlp objects\n",
    "for sentence in docs_test_orig:\n",
    "    sen = nlp(sentence)\n",
    "    \n",
    "    # create list of entity strings\n",
    "    test_entitites.append([word.text for word in sen.ents])\n",
    "\n",
    "# flatten entity list of lists\n",
    "flat_test_entities = [item for sublist in test_entitites for item in sublist]\n",
    "    \n",
    "\n",
    "# filter out entities\n",
    "docs_test = [[word if word not in flat_train_entities else '' for word in sentences] for sentences in docs_test]\n",
    "docs_test[:2]  \n",
    "\n",
    "# drop empty strings\n",
    "docs_test = [[(word) for word in tokens if word] for tokens in docs_test]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only marginal improvement from removing named entities. The reason for this is probably that entities are search for in the original doc which contains \"noise\" that is subsequently removed in the preprocessing. This could mean that the filtering does not work very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.4: Stemming / Lemmatisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs worse with stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from gensim.parsing.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Get the stemmed_tokens\n",
    "docs_train = [[porter_stemmer.stem(word) for word in tokens] for tokens in docs_train]\n",
    "docs_train\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# transform test data 2\n",
    "docs_test = [[porter_stemmer.stem(word) for word in tokens] for tokens in docs_test]\n",
    "docs_test\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.6 Train word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# run to train own model\n",
    "\n",
    "# adopted, taken from from https://medium.com/swlh/sentiment-classification-using-word-embeddings-word2vec-aedf28fbb8ca\n",
    "path_word2vec_model = '0_models/31_word2vec_.model'\n",
    "\n",
    "\n",
    "# Train the Word2Vec Model\n",
    "model = Word2Vec(docs_train, min_count = 1, size = 1000,\\\n",
    "                     workers = 3, window = 3, sg = 1)\n",
    "\n",
    "# store the model\n",
    "model.save(path_word2vec_model)\n",
    "\n",
    "# Load the model from the model file\n",
    "model = Word2Vec.load(path_word2vec_model)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to use the trained model by Google\n",
    "\n",
    "# https://code.google.com/archive/p/word2vec/\n",
    "# https://github.com/RaRe-Technologies/gensim-data\n",
    "# Tutorial: https://towardsdatascience.com/using-word2vec-to-analyze-news-headlines-and-predict-article-success-cdeda5f14751\n",
    "\n",
    "# Load word2vec model (trained on an Google news corpus)\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('0_models/31_word2vec_GoogleNews-vectors-negative300.bin', binary = True) \n",
    "\n",
    "# Check dimension of word vectors\n",
    "model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of vocabulary that counts occurances\n",
    "# source: https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings\n",
    "\n",
    "def build_vocab(sentences, verbose =  True):\n",
    "    \"\"\"\n",
    "    :param sentences: list of list of words\n",
    "    :return: dictionary of words and their count\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab= build_vocab(docs_train)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check % of words included in embedding\n",
    "# source: https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings\n",
    "\n",
    "import operator \n",
    "\n",
    "def check_coverage(vocab,model):\n",
    "    a = {}\n",
    "    oov = {}\n",
    "    k = 0\n",
    "    i = 0\n",
    "    for word in (vocab):\n",
    "        try:\n",
    "            a[word] = model[word]\n",
    "            k += vocab[word]\n",
    "        except:\n",
    "\n",
    "            oov[word] = vocab[word]\n",
    "            i += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
    "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov = check_coverage(vocab,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without stop words removal:\n",
    "94.3% of vocab\n",
    "91.5% of words\n",
    "\n",
    "with stop words removal:\n",
    "92.8% of vocab\n",
    "96.0% of words\n",
    "\n",
    "\n",
    "with manual list of stop words removal:\n",
    "93.0% of vocab\n",
    "96.5% of words\n",
    "\n",
    "with manual list of stop words removal and entity removal:\n",
    "93.5% of vocab\n",
    "96.6% of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print words missing in the embedding sorted by frequency\n",
    "oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique ID of the word\n",
    "word=\"rise\"\n",
    "print(\"Index of the word:\"+ word)\n",
    "print(model.wv.vocab[word].index)\n",
    "\n",
    "# Total number of the words \n",
    "print(len(model.wv.vocab))\n",
    "\n",
    "# Print the size of the word2vec vector for one word\n",
    "print(\"Length of the vector generated for a word\")\n",
    "\n",
    "print(len(model[word]))\n",
    "\n",
    "# Get the mean for the vectors for an example review\n",
    "#print(\"Print the length after taking average of all word vectors in a sentence:\")\n",
    "#print(np.mean([model[token] for token in docs_train[24]], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look-up some similar words\n",
    "#model.most_similar(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transform training data\n",
    "\n",
    "X_train=[]\n",
    "\n",
    "# loop through train documents\n",
    "for i in range(len(docs_train)):\n",
    "    \n",
    "    # take average vector of words per news headline if word is included in the model's vocabulary\n",
    "    X_train.append(np.mean([model[token] for token in docs_train[i] if token in model.vocab], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for each document in the corpus whether its empty\n",
    "is_empty=[False if x.size==1 else True for i,x in enumerate(X_train)]\n",
    "is_empty[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(is_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/linanqiu/word2vec-sentiments/blob/master/word2vec-sentiment.ipynb\n",
    "# source for doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data\n",
    "\n",
    "X_test=[]\n",
    "\n",
    "# loop through train documents\n",
    "for i in range(len(docs_test)):\n",
    "    \n",
    "    # take average vector of words per news headline if word is included in the model's vocabulary\n",
    "    X_test.append(np.mean([model[token] for token in docs_test[i] if token in model.vocab], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.1 Basline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority baseline\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate majority baseline dataframe\n",
    "y_pred_basel = np.full((len(y_train), 1), \"positive\")\n",
    "y_pred_basel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate f-score\n",
    "f1_score(y_train,y_pred_basel,average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.2 SVM - Linear\n",
    "\n",
    "#### Section 4.2.1  Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvm = LinearSVC()\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "# 5 combinations in the grid\n",
    "param_grid = {\n",
    "    'C': [0.5,0.6,0.65,0.69,0.7,0.71,0.75,0.8],\n",
    "    #    'C': [0.05,0.01,0.02,0.1,0.5,0.6,0.7,0.8,0.9,1,1.1,1.2,1.3,1.5,2.0,5,10],\n",
    "    #'max_iter': [5000],\n",
    "    'random_state': [7]\n",
    "}\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search_LSVC = GridSearchCV(lsvm, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True) \n",
    "\n",
    "start = time.time()\n",
    "grid_search_LSVC.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the set of best hyperparameters\n",
    "grid_search_LSVC.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the corresponding f-score\n",
    "grid_search_LSVC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the results of all tested models\n",
    "val_scores = grid_search_LSVC.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_LSVC.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_LSVC.cv_results_[\"params\"]]\n",
    "\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print(val_score, train_score, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the f-scores of the best models in each split\n",
    "\n",
    "svm_lin_split_test_scores = []\n",
    "for x in range(5):\n",
    "    # extract f-score of the best model (at index=0) from each of the 5 splits\n",
    "    val = grid_search_LSVC.cv_results_[f\"split{x}_test_score\"][0]\n",
    "    svm_lin_split_test_scores.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "\n",
    "** With stemming: **\n",
    "\n",
    "Best score semeval val set: C=0.1, val: 74.06% and train: 81.6%\n",
    "\n",
    "Best score semeval own val set: C=0.1, val: 74.2% and train: 81.4%\n",
    "\n",
    "Best score Rise and Fall: C=10, val: 58.7% and train: 60.16%\n",
    "\n",
    "** Without stemming: **\n",
    "\n",
    "Best score semeval own val set: C=0.1, val: 76.0% and train: 82.7%\n",
    "\n",
    "** Without lower casing and stemming: **\n",
    "\n",
    "Best score semeval own val set: C=0.1, val: 76.0% and train: 90.5%\n",
    "\n",
    "** Without lower casing, stemming with removal of numbers and special cases: **\n",
    "\n",
    "Best score semeval own val set: C=1, val: 76.15% and train: 90.5%\n",
    "\n",
    "** Without lower casing, stemming with removal of numbers, special cases, stop words : **\n",
    "\n",
    "Best score semeval own val set: C=0.1, val: 75.5% and train: 83.4%\n",
    "\n",
    "** Without lower casing, stemming with removal of numbers, special cases, manual stop words : **\n",
    "\n",
    "Best score semeval own val set: C=0.7, val: 76.9% and train: 89.6%\n",
    "\n",
    "** Without lower casing, stemming with removal of numbers, special cases, manual stop words and named entity removal: **\n",
    "\n",
    "Best score semeval own val set: C=1, val: 76.32% and train: 91.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4.2.2 SVM -Linear - Store the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store model\n",
    "# create a folder where all trained models will be kept\n",
    "if not os.path.exists(\"0_models\"):\n",
    "    os.makedirs(\"0_models\")\n",
    "    \n",
    "dump(grid_search_LSVC.best_estimator_, '0_models/32_word2vec_Sentiment Analysis_Linear_SVM model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4.2.3 SVM -Linear - Plot results of SVM classifier on reduced dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusted visualisation from https://towardsdatascience.com/a-practical-guide-to-interpreting-and-visualising-support-vector-machines-97d2a5b0564e\n",
    "# reduce dimensions\n",
    "tsvd = TruncatedSVD(n_components=2).fit(X_train)\n",
    "tsvd_2d = tsvd.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import pylab as pl\n",
    "\n",
    "for i in range(0, tsvd_2d.shape[0]):\n",
    "    if y_train[i] == \"negative\":\n",
    "        c1 = pl.scatter(tsvd_2d[i,0],tsvd_2d[i,1],c='r',    marker='o')\n",
    "    elif y_train[i] == \"positive\":\n",
    "        c2 = pl.scatter(tsvd_2d[i,0],tsvd_2d[i,1],c='g',    marker='+')\n",
    "\n",
    "pl.legend([c1, c2], ['negative', 'positive'])\n",
    "pl.title('SVM illustration')\n",
    "pl.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.3 SVM - Poly \n",
    "\n",
    "#### Section 4.3.1 Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_svm = SVC(kernel='poly')\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "# 5 combinations in the grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1,10,15,18,19,20,25],\n",
    "    #'C': [1.6,1.65,1.7,1.725,1.75,1.775,1.8,3,4,5,6,7,8,9,10],\n",
    "    #  'C': [0.01,0.05,0.1,1,1.7,1.8,1.9,2,2.1,2.2,2.3,2.5,3,4,5,6,7,8,9,10],\n",
    "    'gamma': [\"scale\", \"auto\",0.01,0.05, 0.1,0.14,0.15,0.16,0.2,0.5],\n",
    "    'degree': [2],\n",
    "    #'degree': [2,3],\n",
    "    #'max_iter': [5000],\n",
    "    'random_state': [7]\n",
    "}\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search_poly_SVC = GridSearchCV(poly_svm, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True) \n",
    "\n",
    "start = time.time()\n",
    "grid_search_poly_SVC.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the set of best hyperparameters\n",
    "grid_search_poly_SVC.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the corresponding f-score\n",
    "grid_search_poly_SVC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the results of all tested models\n",
    "val_scores = grid_search_poly_SVC.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_poly_SVC.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_poly_SVC.cv_results_[\"params\"]]\n",
    "\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print(val_score, train_score, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "\n",
    "** Without lower casing, stemming with removal of numbers, special cases, manual stop words : **\n",
    "\n",
    "Best score semeval own val set: C=19,degree=\"2\", gamma=\"0.15\", val: 76.4% and train: 94.6%\n",
    "\n",
    "** Without lower casing, stemming with removal of numbers, special cases, manual stop words and named entity removal: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4.3.2 SVM -Poly - Store the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store model\n",
    "# create a folder where all trained models will be kept\n",
    "if not os.path.exists(\"0_models\"):\n",
    "    os.makedirs(\"0_models\")\n",
    "    \n",
    "dump(grid_search_poly_SVC.best_estimator_, '0_models/32_word2vec_Sentiment Analysis_Poly_SVM model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.4 SVM - Rbf \n",
    "\n",
    "#### Section 4.4.1 Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svm =  SVC(kernel='rbf')\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "# 5 combinations in the grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1,5, 10,15,19,20,21,25],\n",
    "    #'C': [1.6,1.65,1.7,1.725,1.75,1.775,1.8,3,4,5,6,7,8,9,10],\n",
    "    #  'C': [0.01,0.05,0.1,1,1.7,1.8,1.9,2,2.1,2.2,2.3,2.5,3,4,5,6,7,8,9,10],\n",
    "    'gamma': [\"scale\", \"auto\",0.01,0.05,0.09, 0.1,0.11,0.12,0.4,0.5],\n",
    "    #'max_iter': [5000],\n",
    "    'random_state': [7]\n",
    "}\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search_rbf_SVC = GridSearchCV(rbf_svm, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True) \n",
    "\n",
    "start = time.time()\n",
    "grid_search_rbf_SVC.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the set of best hyperparameters\n",
    "grid_search_rbf_SVC.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the corresponding f-score\n",
    "grid_search_rbf_SVC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the results of all tested models\n",
    "val_scores = grid_search_rbf_SVC.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_rbf_SVC.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_rbf_SVC.cv_results_[\"params\"]]\n",
    "\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print(val_score, train_score, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the f-scores of the best models in each split\n",
    "\n",
    "svm_rbf_split_test_scores = []\n",
    "for x in range(5):\n",
    "    # extract f-score of the best model (at index=0) from each of the 5 splits\n",
    "    val = grid_search_rbf_SVC.cv_results_[f\"split{x}_test_score\"][0]\n",
    "    svm_rbf_split_test_scores.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "\n",
    "** Without lower casing, stemming with removal of numbers, special cases, manual stop words : **\n",
    "\n",
    "Best score semeval own val set: C=20,gamma=0.1, val: 77.4% and train: 94.9%\n",
    "\n",
    "** Without lower casing, stemming with removal of numbers, special cases, manual stop words and named entity removal: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4.4.2 SVM - Rbf - Store the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store model\n",
    "# create a folder where all trained models will be kept\n",
    "if not os.path.exists(\"0_models\"):\n",
    "    os.makedirs(\"0_models\")\n",
    "    \n",
    "dump(grid_search_rbf_SVC.best_estimator_, '0_models/32_word2vec_Sentiment Analysis_Rbf_SVM model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.5 SVM - Sigmoid \n",
    "\n",
    "#### Section 4.5.1 Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigm_svm =  SVC(kernel='sigmoid')\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "# 5 combinations in the grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1,5, 10,15,20,30,35,40,41,42,45,50],\n",
    "    #'C': [1.6,1.65,1.7,1.725,1.75,1.775,1.8,3,4,5,6,7,8,9,10],\n",
    "    #  'C': [0.01,0.05,0.1,1,1.7,1.8,1.9,2,2.1,2.2,2.3,2.5,3,4,5,6,7,8,9,10],\n",
    "    'gamma': [\"scale\", \"auto\",0.01,0.05,0.09, 0.1,0.11,0.12,0.13,0.2,0.3,0.4,0.5],\n",
    "    #'max_iter': [5000],\n",
    "    'random_state': [7]\n",
    "    }\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search_sigm_SVC = GridSearchCV(sigm_svm, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True) \n",
    "\n",
    "start = time.time()\n",
    "grid_search_sigm_SVC.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the set of best hyperparameters\n",
    "grid_search_sigm_SVC.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the corresponding f-score\n",
    "grid_search_sigm_SVC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the results of all tested models\n",
    "val_scores = grid_search_sigm_SVC.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_sigm_SVC.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_sigm_SVC.cv_results_[\"params\"]]\n",
    "\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print(val_score, train_score, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "\n",
    "** Without lower casing, stemming with removal of numbers, special cases, manual stop words : **\n",
    "\n",
    "Best score semeval own val set: C=26,gamma=, val: 75.4% and train: 88.5%\n",
    "\n",
    "** Without lower casing, stemming with removal of numbers, special cases, manual stop words and named entity removal: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4.5.2 SVM - Sigmoid - Store the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store model\n",
    "# create a folder where all trained models will be kept\n",
    "if not os.path.exists(\"0_models\"):\n",
    "    os.makedirs(\"0_models\")\n",
    "    \n",
    "dump(grid_search_sigm_SVC.best_estimator_, '0_models/32_word2vec_Sentiment Analysis_Sigmoid_SVM model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: Summary SVM\n",
    "Linear: 0.768800703862267 0.8958871182923149 {'C': 0.7, 'random_state': 7}\n",
    "\n",
    "Poly:   0.7635545031027572 0.9458602940788126 {'C': 19, 'degree': 2, 'gamma': 0.15, 'random_state': 7}\n",
    "\n",
    "Rbf:    0.7738981131931123 0.9491613701359167 {'C': 20, 'gamma': 0.1, 'random_state': 7}\n",
    "\n",
    "Sigmoid: 0.7589640372372386 0.898002240325126 {'C': 41, 'gamma': 0.1, 'random_state': 7}\n",
    "\n",
    "Best performance rbf kernel, followed by linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.6 Random Forest \n",
    "\n",
    "#### Section 4.6.1 Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "# 4 x 3 x 2 = 24 combinations in the grid\n",
    "param_grid = {\n",
    "    'n_estimators': [10,50,85,89,90,91,95],\n",
    "    #'n_estimators': [10,20,30,40,50,60,70,80,85,90,95,300],\n",
    "    #'n_estimators': [10, 100, 250,275,300],\n",
    "   # 'max_depth': [3, 5, 15,18,19,20],\n",
    "    'max_depth': [10,14, 15,16],\n",
    "    #'min_samples_split': [2,3,4,5,6,10],\n",
    "    'min_samples_split': [3,4,5],\n",
    "    'random_state': [7]\n",
    "}\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True) \n",
    "\n",
    "start = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the set of best hyperparameters\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the corresponding f-score\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the results of all tested models\n",
    "val_scores = grid_search.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search.cv_results_[\"params\"]]\n",
    "\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print(val_score, train_score, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4.6.2  Random Forest - Store the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store model\n",
    "# create a folder where all trained models will be kept\n",
    "if not os.path.exists(\"0_models\"):\n",
    "    os.makedirs(\"0_models\")\n",
    "    \n",
    "dump(grid_search.best_estimator_, '0_models/32_word2vec_Sentiment Analysis_Random Forest_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "\n",
    "** Without lower casing, stemming with removal of numbers, special cases, manual stop words : **\n",
    "\n",
    "Best score semeval own val set: ;max_depth=20, min samples split: 5, n estimators 300, val: 70.8% and train: 98.5%\n",
    "\n",
    "** Without lower casing, stemming with removal of numbers, special cases, manual stop words and named entity removal: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.7 Decision Tree \n",
    "\n",
    "#### Section 4.7.1  Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state=7)\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "# 3 x 2 = 24 combinations in the grid\n",
    "param_grid = {\n",
    "    \n",
    "    'criterion':['gini', 'entropy'],\n",
    "    'max_depth': [5,10,13,14,15,16,17,18,19,20, 30],\n",
    "    'min_samples_split': [5,7,8,9,10, 20, 50],\n",
    "    'min_samples_leaf': [1,2,3,5]\n",
    "}\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search = GridSearchCV(dtree, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True) \n",
    "\n",
    "start = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the set of best hyperparameters\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the corresponding f-score\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the results of all tested models\n",
    "val_scores = grid_search.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search.cv_results_[\"params\"]]\n",
    "\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print(val_score, train_score, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4.7.2  Decision Tree - Store the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store model\n",
    "# create a folder where all trained models will be kept\n",
    "if not os.path.exists(\"0_models\"):\n",
    "    os.makedirs(\"0_models\")\n",
    "    \n",
    "dump(grid_search.best_estimator_, '0_models/32_word2vec_Sentiment Analysis_Decision Tree model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "\n",
    "** Without lower casing, stemming with removal of numbers, special cases, manual stop words : **\n",
    "\n",
    "Best score semeval own val set: max depth > 15 --> overfitting, val:65.3% and train: 96.3%*\n",
    "\n",
    "** Without lower casing, stemming with removal of numbers, special cases, manual stop words and named entity removal: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.8 Naive Bayes\n",
    "\n",
    "#### Section 4.8.1  Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# no hyperparameters to tune, but use GridSearch for comparability of results\n",
    "\n",
    "gaussNB = GaussianNB()\n",
    "\n",
    "# specify the hyperparameters and their values\n",
    "param_grid = {}\n",
    "\n",
    "# we'll use 5-fold cross-validation\n",
    "grid_search = GridSearchCV(gaussNB, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True) \n",
    "\n",
    "start = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the set of best hyperparameters\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the corresponding f-score\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the results of all tested models\n",
    "val_scores = grid_search.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search.cv_results_[\"params\"]]\n",
    "\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print(val_score, train_score, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4.8.2  Naive Bayes - Store the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store model\n",
    "# create a folder where all trained models will be kept\n",
    "if not os.path.exists(\"0_models\"):\n",
    "    os.makedirs(\"0_models\")\n",
    "    \n",
    "dump(grid_search.best_estimator_, '0_models/32_word2vec_Sentiment Analysis_Gaussian NB model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "\n",
    "** Without lower casing, stemming with removal of numbers, special cases, manual stop words : **\n",
    "\n",
    "Best score semeval own val set: standard settings, val: 68.1% and train: 74.4%\n",
    "\n",
    "** Without lower casing, stemming with removal of numbers, special cases, manual stop words and named entity removal: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rand. Forest: 0.728244519135879 0.9851823501222633 {'max_depth': 15, 'min_samples_split': 4, 'n_estimators': 90, 'random_state': 7}'\n",
    "\n",
    "Decision Tree: 0.6542735047016043 0.9595464543787842 {'criterion': 'gini', 'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 8}\n",
    "\n",
    "Naive Bayes: 0.6812015083736931 0.7435447202399154 {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.8 Text performance differences of best performing models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "# return the t-score and a two-tailed p-value\n",
    "ttest_ind(svm_lin_split_test_scores, svm_rbf_split_test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Evaluate the two most promising model on the test data\n",
    "\n",
    "### Section 5.1 Load the best models and calculate F1-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model\n",
    "best_linear_svm = load(\"0_models/32_word2vec_Sentiment Analysis_Linear_SVM model.joblib\")\n",
    "\n",
    "# use the best model to make predictions on the test set\n",
    "y_hat = best_linear_svm.predict(X_test)\n",
    "\n",
    "# Print marco-averaged precision, recall and f-score\n",
    "p, r, f, s = precision_recall_fscore_support(y_test, y_hat, average=\"macro\")\n",
    "print(\"Support Vector Machines: Linear\")\n",
    "print(f\"Precision: {p}\")\n",
    "print(f\"Recall: {r}\")\n",
    "print(f\"F score: {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the best model\n",
    "best_model = load(\"0_models/32_word2vec_Sentiment Analysis_Rbf_SVM model.joblib\")\n",
    "\n",
    "# use the best model to make predictions on the test set\n",
    "y_hat = best_model.predict(X_test)\n",
    "\n",
    "# Print marco-averaged precision, recall and f-score\n",
    "p, r, f, s = precision_recall_fscore_support(y_test, y_hat, average=\"macro\")\n",
    "print(\"Support Vector Machines: Rbf\")\n",
    "print(f\"Precision: {p}\")\n",
    "print(f\"Recall: {r}\")\n",
    "print(f\"F score: {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print averaged precision, recall and f-score for each class\n",
    "p, r, f, s = precision_recall_fscore_support(y_test, y_hat, average=None)\n",
    "print(\"Support Vector Machines: Rbf: Classes\")\n",
    "print(f\"Precision: {p}\")\n",
    "print(f\"Recall: {r}\")\n",
    "print(f\"F score: {f}\")\n",
    "print(f\"Support: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5.2 Print confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix=plot_confusion_matrix(best_model, X_test, y_test,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize='true',\n",
    "                                 values_format=\".1%\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store figure to image\n",
    "conf_matrix.figure_.savefig('Confusion_matrix_test.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "\n",
    "Without lower casing, stemming and with removal of numbers and special characters:\n",
    "\n",
    "Google Corpus News + Semeval own val\n",
    "Val:neg-neg: 0.65, pos-pos:0.89\n",
    "Train: neg-neg: 0.91, pos-pos:0.97\n",
    "\n",
    "Without lower casing, stemming and with removal of numbers, special characters and named entities:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Classify the real data \n",
    "\n",
    "### Section 6.1: Load data, do all steps of preprocessing and apply the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word2vec model (trained on an Google news corpus)\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('0_models/31_word2vec_GoogleNews-vectors-negative300.bin', binary = True) \n",
    "\n",
    "# load the best model\n",
    "best_model = load(\"0_models/32_word2vec_Sentiment Analysis_Rbf_SVM model.joblib\")\n",
    "\n",
    "# https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/\n",
    "# https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocessor (token):\n",
    "  \n",
    "    # remove special characters (matches all characters not specified)\n",
    "    #pattern = r'[^a-zA-z0-9\\s]'\n",
    "    pattern = r'[^a-zA-z0-9]'\n",
    "    text = re.sub(pattern, '', token)\n",
    "    \n",
    "    # remove numbers\n",
    "    if bool(re.search(r'\\d', text)):\n",
    "        text = re.sub('[0-9]{5,}', '#####', text)\n",
    "        text = re.sub('[0-9]{4}', '####', text)\n",
    "        text = re.sub('[0-9]{3}', '###', text)\n",
    "        text = re.sub('[0-9]{2}', '##', text)\n",
    "        text = re.sub('[0-9]{1}', '#', text)\n",
    "        \n",
    "    # remove missspelling (unlikley in newswires, so no) \n",
    "    \n",
    "    # removing contractions (maybe ?)\n",
    "    \n",
    "    # remove stop words\n",
    "    #stopWords = set(stopwords.words('english'))\n",
    "    stopWords = [\"to\",\"of\",\"and\",\"a\"]\n",
    "    \n",
    "    if text in stopWords:\n",
    "        text=''\n",
    "           \n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path=\"../01_Data/01_Eikon/1_Headlines/3_WRDS_SP 500 Headlines/2019_03_01_to_2020_04_30_Headlines_SP500.csv\"\n",
    "#path=\"../01_Data/01_Eikon/1_Headlines/4_WRDS_SP 500 Headlines completed/2019_03_01_to_2020_06_30_Headlines_SP500.csv\"\n",
    "\n",
    "path=\"../01_Data/01_Eikon/1_Headlines/4_WRDS_SP 500 Headlines completed/2019_03_01_to_2020_06_30_Headlines_SP500_filt.csv\"\n",
    "\n",
    "\n",
    "df_sp500hl = pd.read_csv(path)\n",
    "df_sp500hl.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500hl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "\n",
    "# Dictionary of columns to replace\n",
    "dict_rep= {\"versionCreated\": \"DateTime\",\n",
    "           \"versionCreated.1\": \"Date\"}\n",
    "\n",
    "# Replace column names \n",
    "df_sp500hl.rename(columns = dict_rep, inplace = True) \n",
    "\n",
    "#df_sp500_scores.Date= pd.to_datetime(df_sp500_scores.Date).date\n",
    "df_sp500hl.set_index(\"Date\",inplace=True)\n",
    "\n",
    "\n",
    "df_sp500hl.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500hl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load relevant columns into own dataframe\n",
    "docs_real=df_sp500hl[\"text\"][:]\n",
    "docs_real_orig = docs_real.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform real data\n",
    "docs_real = [nltk.word_tokenize(line) for line in docs_real.values]\n",
    "docs_real[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count words per headline\n",
    "list_words_per_hl=[len(x) for x in docs_real]\n",
    "list_words_per_hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return average number of word per headline\n",
    "np.mean(list_words_per_hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return stdev \n",
    "np.std(list_words_per_hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of headlines that relate to stocks\n",
    "count_stock_rel_news=[any([y in [\"share\", \"shares\", \"stock\", \"equity\", \"equities\"] for y in x]) for x in docs_real]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display number of headlines containin one of the above words\n",
    "sum(count_stock_rel_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if code works as expected\n",
    "z = [[\"moin\",\"eikon\",\"mama\",\"test\"],[\"equity\"],[\"Hallo\", \"wie\",\"gehts\"],[\"shares\", \"wie\",\"gehts\"]]\n",
    "\n",
    "# count number of headlines that relate to stocks\n",
    "test=[any([y in [\"share\", \"shares\", \"stock\", \"equity\", \"equities\"] for y in x]) for x in z]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprocessor\n",
    "docs_real = [[preprocessor(word) for word in tokens] for tokens in docs_real]\n",
    "\n",
    "# drop empty strings\n",
    "docs_real = [[(word) for word in tokens if word] for tokens in docs_real]\n",
    "print(docs_real[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count words per headline\n",
    "list_words_per_hl=[len(x) for x in docs_real]\n",
    "list_words_per_hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(list_words_per_hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# remove entities\n",
    "\n",
    "real_entitites=[]\n",
    "\n",
    "# loop through train documents and create nlp objects\n",
    "for sentence in docs_real_orig:\n",
    "    sen = nlp(sentence)\n",
    "    \n",
    "    # create list of entity strings\n",
    "    real_entitites.append([word.text for word in sen.ents])\n",
    "\n",
    "# flatten entity list of lists\n",
    "flat_real_entitites = [item for sublist in real_entitites for item in sublist]\n",
    "    \n",
    "#print(flat_train_entities[:10])\n",
    "\n",
    "# filter out entities\n",
    "docs_real = [[word if word not in flat_real_entitites else '' for word in sentences] for sentences in docs_real]\n",
    "docs_real[:2]  \n",
    "\n",
    "# drop empty strings\n",
    "docs_real = [[(word) for word in tokens if word] for tokens in docs_real]\n",
    "print(docs_real[:3])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real=[]\n",
    "\n",
    "# loop through real documents\n",
    "for i in range(len(docs_real)):\n",
    "    # take average vector of words per news headline if word is included in model \n",
    "    X_real.append(np.mean([model[token] for token in docs_real[i] if token in model.vocab], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for each document in the corpus whether its empty\n",
    "is_empty=[False if x.size==1 else True for i,x in enumerate(X_real)]\n",
    "is_empty[2864:2867]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the documents without words in the model\n",
    "from itertools import compress\n",
    "X_real=list(compress(X_real, is_empty))\n",
    "len(X_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the documents without words in the documents\n",
    "df_sp500hl=df_sp500hl[is_empty]\n",
    "df_sp500hl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sp500hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the best model to make predictions on the real set\n",
    "df_sp500hl[\"Sentiment\"] = best_model.predict(X_real)\n",
    "df_sp500hl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create seperate columns for negative and positive\n",
    "df_sp500hl[\"Sent_pos\"] = [1 if x==\"positive\" else 0  for x in df_sp500hl[\"Sentiment\"]]\n",
    "df_sp500hl[\"Sent_neg\"] = [-1 if x==\"negative\" else 0 for x in df_sp500hl[\"Sentiment\"]]\n",
    "df_sp500hl[\"Sent_abs\"] = [1 if x==\"positive\" else -1 for x in df_sp500hl[\"Sentiment\"]]\n",
    "\n",
    "df_sp500hl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source about switching from LinearSVC to SVC to obtain actual probabilities \n",
    "# https://stackoverflow.com/questions/26478000/converting-linearsvcs-decision-function-to-probabilities-scikit-learn-python\n",
    "# I use the confidence, as probabilities are computationally intense and the calc. has drawbacks / is critised in the documentation\n",
    "\n",
    "df_sp500hl[\"Sent_conf_abs\"]=best_model.decision_function(X_real)\n",
    "df_sp500hl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create seperate columns for negative and positive\n",
    "df_sp500hl[\"Sent_conf_pos\"] = [x if x>0 else 0  for x in df_sp500hl[\"Sent_conf_abs\"]]\n",
    "df_sp500hl[\"Sent_conf_neg\"] = [x if x<0 else 0 for x in df_sp500hl[\"Sent_conf_abs\"]]\n",
    "df_sp500hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print most confident positive news\n",
    "df_sp500hl.nlargest(10,\"Sent_conf_abs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print most confident negative news\n",
    "df_sp500hl.nsmallest(10,\"Sent_conf_abs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sentiment scores for confident classifications only\n",
    "\n",
    "threshold= 1\n",
    "\n",
    "df_sp500hl[\"Sent_pos_filt\"] = [1 if x>=threshold else 0 for x in df_sp500hl[\"Sent_conf_abs\"]]\n",
    "df_sp500hl[\"Sent_neg_filt\"] = [-1 if x<=-threshold else 0 for x in df_sp500hl[\"Sent_conf_abs\"]]\n",
    "df_sp500hl[\"Sent_abs_filt\"] = df_sp500hl[\"Sent_pos_filt\"]+df_sp500hl[\"Sent_neg_filt\"]\n",
    "\n",
    "df_sp500hl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500hl.Sent_pos.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df_sp500hl.Sent_neg.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500hl[\"Sent_pos_filt\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store\n",
    "df_sp500hl.nlargest(500,\"Sent_conf_abs\").to_excel(\"../01_Data/10_Modelling/32_word2vec_Sentiment Analysis_Semeval_Headlines most postive.xlsx\")\n",
    "df_sp500hl.nsmallest(500,\"Sent_conf_abs\").to_excel(\"../01_Data/10_Modelling/32_word2vec_Sentiment Analysis__Semeval_Headlines most negative.xlsx\")\n",
    "df_sp500hl.to_csv(\"../01_Data/10_Modelling/32_word2vec_Sentiment Analysis_Semeval__Headlines complete incl score and confidence.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics / Analysis of Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classified headlines from csv\n",
    "df_sp500hl=pd.read_csv(\"../01_Data/10_Modelling/32_word2vec_Sentiment Analysis_Semeval__Headlines complete incl score and confidence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show header\n",
    "df_sp500hl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show descriptive statistics of confidence\n",
    "df_sp500hl.Sent_conf_abs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500hl.Sent_conf_abs.kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500hl.Sent_conf_abs.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show histogram of confidence\n",
    "df_sp500hl.Sent_conf_abs.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'figure.figsize':(10,5), 'figure.dpi':100})\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "# Hide the top and right spines of the axis\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.xticks(np.arange(-6,#min(df_sp500hl.Sent_conf_abs), \n",
    "                    9,# max(df_sp500hl.Sent_conf_abs)+1\n",
    "                      1.0))\n",
    "\n",
    "ax.get_yaxis().set_major_formatter(\n",
    "mpl.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "# Plot Histogram on x\n",
    "x = df_sp500hl.Sent_conf_abs\n",
    "plt.hist(x, bins=50)\n",
    "plt.gca().set(#title='Histogram', \n",
    "              ylabel='Frequency',xlabel=\"Sentiment Confidence\")\n",
    "\n",
    "\n",
    "# store to image\n",
    "plt.savefig('Hist_sentiment_Real.png',dpi=300, transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show density curve /distribution of confidence\n",
    "#df_sp500hl.Sent_conf_abs.plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "density = gaussian_kde(df_sp500hl.Sent_conf_abs)\n",
    "xs = np.linspace(-5,5,200)\n",
    "#density.covariance_factor = lambda : .25\n",
    "#density._compute_covariance()\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(xs,density(xs))\n",
    "\n",
    "# Add the x and y-axis labels\n",
    "plt.xlabel('Sentiment Confidence')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "\n",
    "# Hide the top and right spines of the axis\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "#loc = plticker.MultipleLocator(base=1.0) # this locator puts ticks at regular intervals\n",
    "#ax.xaxis.set_major_locator(loc)\n",
    "plt.xticks(np.arange(-4,#min(df_sp500hl.Sent_conf_abs), \n",
    "                    5,# max(df_sp500hl.Sent_conf_abs)+1\n",
    "                      1.0))\n",
    "\n",
    "# store to image\n",
    "plt.savefig('KDE_plot_sentiment_Real.png',dpi=300, transparent=False, bbox_inches='tight')\n",
    "\n",
    "# display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out irrelevant news, duplicated news (same score, same company, same day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 6.2: Transform news sentiment to daily measures of firm specfifc sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create one grouped Dataframe \n",
    "# (that sums up the accidents for each categorical field)\n",
    "\n",
    "# Define fields for grouping\n",
    "group_list= [\"Date\",\n",
    "             \"RIC\"\n",
    "             ]\n",
    "\n",
    "# Define components to compute target variable\n",
    "dict_aggregations= {\"Sent_abs\": \"sum\", # = overall sentiment score  \n",
    "                    \"Sent_neg\": \"sum\", # = number of negative news per day \n",
    "                    \"Sent_pos\": \"sum\",  # = number of positive news per day \n",
    "                    \"Sent_abs_filt\": \"sum\", # = overall sentiment score filtered \n",
    "                    \"Sent_neg_filt\": \"sum\", # = number of negative news per day filtered\n",
    "                    \"Sent_pos_filt\": \"sum\",  # = number of positive news per day filtered\n",
    "                    \"Sent_conf_abs\": \"sum\", # = sentiment score based on confidence\n",
    "                    \"Sent_conf_pos\": \"sum\",\n",
    "                    \"Sent_conf_neg\": \"sum\",\n",
    "                    \"Sentiment\": \"count\" # =number of articles published\n",
    "                   }\n",
    "\n",
    "# Calculate daily scores for each company / Create aggregated tables\n",
    "df_sp500_scores = df_sp500hl.groupby(group_list).agg(dict_aggregations).reset_index()\n",
    "df_sp500_scores.set_index([\"Date\",\"RIC\"], inplace=True)\n",
    "\n",
    "# Replace column names for both test and train data\n",
    "df_sp500_scores.rename(columns = {\"Sentiment\": \"News_vol\"}, inplace = True) \n",
    "\n",
    "df_sp500_scores.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average sentiment\n",
    "df_sp500_scores[\"Sent_avg\"]=df_sp500_scores[\"Sent_abs\"]/df_sp500_scores[\"News_vol\"]\n",
    "df_sp500_scores[\"Sent_avg_filt\"]=df_sp500_scores[\"Sent_abs_filt\"]/df_sp500_scores[\"News_vol\"]\n",
    "df_sp500_scores[\"Sent_avg_conf\"]=df_sp500_scores[\"Sent_conf_abs\"]/df_sp500_scores[\"News_vol\"]\n",
    "df_sp500_scores[\"Sent_avg_conf_neg\"]=df_sp500_scores[\"Sent_conf_neg\"]/df_sp500_scores[\"News_vol\"]\n",
    "df_sp500_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ratios between positive and negative\n",
    "df_sp500_scores[\"Sent_ratio\"]=np.log((1+df_sp500_scores[\"Sent_pos\"])/(1+df_sp500_scores[\"Sent_neg\"]*-1))\n",
    "df_sp500_scores[\"Sent_ratio_filt\"]=np.log((1+df_sp500_scores[\"Sent_pos_filt\"])/(1+df_sp500_scores[\"Sent_neg_filt\"]*-1))\n",
    "df_sp500_scores[\"Sent_ratio_conf\"]=np.log((1+df_sp500_scores[\"Sent_conf_pos\"])/(1+df_sp500_scores[\"Sent_conf_neg\"]*-1))\n",
    "\n",
    "\n",
    "df_sp500_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy to manipulate / for visualisations\n",
    "df_sp500_scores_vis=df_sp500_scores.copy()\n",
    "df_sp500_scores_vis=df_sp500_scores_vis.reset_index()\n",
    "df_sp500_scores_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500_scores_vis.to_csv(\"../01_Data/10_Modelling/32_word2vec_Sentiment Analysis_Semeval__Headlines for visualisations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data to format needed for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unstack table\n",
    "df_sp500_scores=df_sp500_scores.unstack()\n",
    "df_sp500_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce multi index to single column index\n",
    "level_one = df_sp500_scores.columns.get_level_values(0).astype(str)\n",
    "level_two = df_sp500_scores.columns.get_level_values(1).astype(str)\n",
    "df_sp500_scores.columns = level_one+\"_\" + level_two \n",
    "df_sp500_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index to datetime\n",
    "df_sp500_scores.index= pd.to_datetime(df_sp500_scores.index).date\n",
    "df_sp500_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index so that date becomes a column again\n",
    "df_sp500_scores.reset_index()\n",
    "df_sp500_scores.rename(columns =  {\"index\": \"Date\"}, inplace = True)\n",
    "df_sp500_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500_scores.index.name = 'Date'\n",
    "df_sp500_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store to excel \n",
    "df_sp500_scores.to_excel(\"../01_Data/10_Modelling/32_word2vec_Sentiment Analysis_Semeval_Daily_firm_specific_sentiment_scores.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Visualisation and descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# Edit the font, font size, and axes width\n",
    "mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [8.0, 8.0]\n",
    "mpl.rcParams['figure.dpi'] = 120\n",
    "mpl.rcParams['savefig.dpi'] = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sp500_scores_vis=pd.read_csv(\"../01_Data/10_Modelling/32_word2vec_Sentiment Analysis_Semeval__Headlines for visualisations.csv\", index_col=\"Unnamed: 0\")\n",
    "df_sp500_scores_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out Moodys\n",
    "df_sp500_scores_vis = df_sp500_scores_vis[df_sp500_scores_vis.RIC!=\"MCO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500_scores_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by date\n",
    "df_sp500_scores_vis=df_sp500_scores_vis.sort_values(by=\"Date\")\n",
    "df_sp500_scores_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data for Apple\n",
    "#df_sp500_scores_vis[df_sp500_scores_vis.RIC==\"AAPL.O\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate average sentiment by company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average sentiment by company\n",
    "df_comp_avg_sent=pd.pivot_table(df_sp500_scores_vis,index=[\"RIC\"],\\\n",
    "               #values=[\"Sent_conf_neg\"],\\\n",
    "               aggfunc=(np.mean, min, max,sum),fill_value=np.NaN)\n",
    "df_comp_avg_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store in excel\n",
    "df_comp_avg_sent.to_excel(\"../01_Data/10_Modelling/32_word2vec_Sentiment Analysis_Semeval_Headlines AVG Sentiment by company.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot weekly average sentiment overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sp500_scores_vis.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500_scores_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500_scores_vis[\"Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500_scores_vis.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500_scores_vis[\"Date\"]=pd.to_datetime(df_sp500_scores_vis[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500_scores_vis.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500_scores_vis['weeknum'] = df_sp500_scores_vis[\"Date\"].apply(lambda x:x.isocalendar()[1])\n",
    "df_sp500_scores_vis['year'] = df_sp500_scores_vis[\"Date\"].apply(lambda x:x.isocalendar()[0])\n",
    "df_sp500_scores_vis[\"Week_display\"]=df_sp500_scores_vis['year'].astype(str)+\"-\"+df_sp500_scores_vis['weeknum'].astype(str)\n",
    "df_sp500_scores_vis[\"Week\"]=df_sp500_scores_vis['weeknum'].astype(str)\n",
    "df_sp500_scores_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500_scores_vis['ISO'] = df_sp500_scores_vis['year'].astype(str) + '-W' + df_sp500_scores_vis['Week'].astype(str) + '-1'\n",
    "\n",
    "# Create column that shows first day of week as \"Week\"\n",
    "df_sp500_scores_vis['Week'] = df_sp500_scores_vis['ISO'].map(lambda x: datetime.datetime.strptime(x, \"%G-W%V-%u\"))\n",
    "df_sp500_scores_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sp500_scores_vis[\"Week\"]=df_sp500_scores_vis[\"Date\"].dt.strftime('%Y-%V')\n",
    "df_sp500_scores_vis[\"Month\"]=df_sp500_scores_vis[\"Date\"].dt.strftime('%Y-%m')\n",
    "df_sp500_scores_vis.sort_values(by=\"Week\")\n",
    "df_sp500_scores_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500_scores_vis[\"Week\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show average sentiment per week\n",
    "df_daily_avg_sent=pd.pivot_table(df_sp500_scores_vis,index=[\"Date\"],\\\n",
    "               #values=[\"Sent_avg\"],\\\n",
    "              # values=[\"Sent_avg_filt\"],\\\n",
    "               values=[\"Sent_avg\"],\\\n",
    "               aggfunc=[np.mean],fill_value=np.NaN)\n",
    "df_daily_avg_sent.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_avg_sent.loc[\"03.03.2019\":\"29.06.2020\"].plot(figsize=(15,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot overall sentiment by week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show average sentiment per week\n",
    "df_weekly_avg_sent=pd.pivot_table(df_sp500_scores_vis,index=[\"Week\"],\\\n",
    "               values=[\"Sent_avg_conf\"],\\\n",
    "              # values=[\"Sent_avg\"],\\\n",
    "               #values=[\"Sent_neg_filt\",\"Sent_neg\"],\\\n",
    "               aggfunc=[np.mean],fill_value=np.NaN)\n",
    "\n",
    "# drop 2 level columns\n",
    "df_weekly_avg_sent.columns = df_weekly_avg_sent.columns.map('_'.join)\n",
    "\n",
    "\n",
    "#df_daily_avg_sent.plot(figsize=(15,5))\n",
    "df_weekly_avg_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out first and last week\n",
    "#df_weekly_avg_sent=df_weekly_avg_sent.loc[\"2019-03-03\":\"2020-06-28\"]\n",
    "df_weekly_avg_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colourWheel =['#00008b','#a6e9ff']\n",
    "colourWheel =['#00008b','#000000']\n",
    "\n",
    "#plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "alphaVal = 1\n",
    "linethick=2\n",
    "ax.plot(df_weekly_avg_sent.index,\n",
    "        df_weekly_avg_sent,\n",
    "        color=\"#00008b\",\n",
    "        #color=\"blue\",\n",
    "        linestyle = '-',\n",
    "        #dashes=dashesStyles[j%len(dashesStyles)],\n",
    "        lw=linethick,\n",
    "        label=\"AVG Sent\",\n",
    "        alpha=alphaVal)\n",
    "\n",
    "ax.set_xlabel('')\n",
    "#ax.yaxis.set_major_formatter(ScalarFormatter())\n",
    "#ax.yaxis.major.formatter._useMathText = True\n",
    "#ax.yaxis.set_minor_locator(  AutoMinorLocator(5))\n",
    "#ax.xaxis.set_minor_locator(  AutoMinorLocator(5))\n",
    "#ax.yaxis.set_label_coords(0.63,1.01)\n",
    "#ax.yaxis.tick_right()\n",
    "plt.xticks(rotation=60)\n",
    "#fig.autofmt_xdate()\n",
    "\n",
    "import matplotlib.ticker as plticker\n",
    "#loc = plticker.MultipleLocator(base=25.0) # this locator puts ticks at regular intervals\n",
    "#ax.xaxis.set_major_locator(loc)\n",
    "\n",
    "\n",
    "#nameOfPlot = 'GDP per hour (constant prices, indexed to 2007)'\n",
    "plt.xlabel(\"First day of the week\",rotation=0)\n",
    "plt.ylabel(\"Average Sentiment Confidence\",rotation=90)\n",
    "#ax.legend(frameon=False, title=\"Decil\",loc='lower left',ncol=2,handlelength=2)\n",
    "\n",
    "# Hide the top and right spines of the axis\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# store to image\n",
    "plt.savefig('Average Sentiment by week.png',dpi=300, transparent=False, bbox_inches='tight')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show average sentiment per week\n",
    "df_weekly_avg_sent_2=pd.pivot_table(df_sp500_scores_vis,index=[\"Week\"],\\\n",
    "               values=[\"Sent_avg_conf\",\"Sent_conf_pos\",\"Sent_conf_neg\",\"News_vol\"],\\\n",
    "              # values=[\"Sent_avg\"],\\\n",
    "               #values=[\"Sent_neg_filt\",\"Sent_neg\"],\\\n",
    "               aggfunc=[np.mean,\"sum\"],fill_value=np.NaN)\n",
    "\n",
    "# drop 2 level columns\n",
    "df_weekly_avg_sent_2.columns = df_weekly_avg_sent_2.columns.map('_'.join)\n",
    "\n",
    "\n",
    "#df_daily_avg_sent.plot(figsize=(15,5))\n",
    "df_weekly_avg_sent_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out first and last week\n",
    "#df_weekly_avg_sent_2=df_weekly_avg_sent_2.loc[\"2019-03-03\":\"2020-06-28\"]\n",
    "df_weekly_avg_sent_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_weekly_avg_sent_2[df_weekly_avg_sent_2.index==\"2019-12-23\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df_mean_percentiles_trans[:\"29.06.2020\"].plot(figsize=(12,8),rot=60)\n",
    "#colourWheel =['#00008b','#a6e9ff']\n",
    "colourWheel =['#00008b','#000000']\n",
    "\n",
    "#plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "ax2 = ax.twinx()  # set up the 2nd axis\n",
    "\n",
    "alphaVal = 1\n",
    "linethick=2\n",
    "\n",
    "ax2.bar(df_weekly_avg_sent_2.index,\n",
    "        df_weekly_avg_sent_2.sum_News_vol,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2, \n",
    "        width=5,\n",
    "        #color=\"blue\",\n",
    "        label=\"News Vol\",\n",
    "        #alpha=alphaVal\n",
    "       )\n",
    "\n",
    "ax.plot(df_weekly_avg_sent_2.index,\n",
    "        df_weekly_avg_sent_2.mean_Sent_avg_conf,\n",
    "        color=\"#00008b\",\n",
    "        #color=\"blue\",\n",
    "        linestyle = '-',\n",
    "        #dashes=dashesStyles[j%len(dashesStyles)],\n",
    "        lw=linethick,\n",
    "        label=\"Sent AVG Conf\",\n",
    "       # alpha=alphaVal\n",
    "       )\n",
    "\n",
    "\n",
    "\"\"\"ax.plot(df_weekly_avg_sent_2.index,\n",
    "        df_weekly_avg_sent_2.mean_Sent_conf_neg,\n",
    "        color=\"#000000\",\n",
    "        #color=\"blue\",\n",
    "        linestyle = '-',\n",
    "        #dashes=dashesStyles[j%len(dashesStyles)],\n",
    "        lw=linethick,\n",
    "        label=series,\n",
    "        alpha=alphaVal)\n",
    "\n",
    "ax.plot(df_weekly_avg_sent_2.index,\n",
    "        df_weekly_avg_sent_2.mean_Sent_conf_pos,\n",
    "        color=\"#00000b\",\n",
    "        #color=\"blue\",\n",
    "        linestyle = '-',\n",
    "        #dashes=dashesStyles[j%len(dashesStyles)],\n",
    "        lw=linethick,\n",
    "        label=series,\n",
    "        alpha=alphaVal)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "#df_weekly_avg_sent_2.sum_News_vol.plot(secondary_y=True)\n",
    "\n",
    "ax.set_xlabel('')\n",
    "#ax.yaxis.set_major_formatter(ScalarFormatter())\n",
    "#ax.yaxis.major.formatter._useMathText = True\n",
    "#ax.yaxis.set_minor_locator(  AutoMinorLocator(5))\n",
    "#ax.xaxis.set_minor_locator(  AutoMinorLocator(5))\n",
    "#ax.yaxis.set_label_coords(0.63,1.01)\n",
    "#ax.yaxis.tick_right()\n",
    "\n",
    "#fig.autofmt_xdate()\n",
    "\n",
    "#nameOfPlot = 'GDP per hour (constant prices, indexed to 2007)'\n",
    "ax.set_xlabel(\"Month\",rotation=0)\n",
    "#plt.ylabel(\"Average Sentiment Confidence\",rotation=90)\n",
    "ax.set_ylabel('Average Sentiment Confidence')\n",
    "ax2.set_ylabel('Number of News Headlines')\n",
    "\n",
    "# Set number format for second y axis\n",
    "ax2.get_yaxis().set_major_formatter(\n",
    "mpl.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "# store to image\n",
    "plt.savefig('Average Sentiment and News Vol. by week.png',dpi=300, transparent=False, bbox_inches='tight')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add S&P index to chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp=pd.read_excel(\"../01_Data/01_Eikon/2_Prices/2_Full Stock Prices data/2_WRDS_SP 500 Full stock price.xlsx\",usecols=[\"Date\",\".SPX\"])\n",
    "df_sp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp[\"Date\"]=pd.to_datetime(df_sp[\"Date\"])\n",
    "df_sp['weeknum'] = df_sp[\"Date\"].apply(lambda x:x.isocalendar()[1])\n",
    "df_sp[\"Week\"]=df_sp['weeknum'].astype(str)\n",
    "df_sp['year'] = df_sp[\"Date\"].apply(lambda x:x.isocalendar()[0])\n",
    "df_sp['ISO'] = df_sp['year'].astype(str) + '-W' + df_sp['Week'].astype(str) + '-1'\n",
    "df_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column that shows first day of week as \"Week\"\n",
    "df_sp['Week'] = df_sp['ISO'].map(lambda x: datetime.datetime.strptime(x, \"%G-W%V-%u\"))\n",
    "\n",
    "# Sort by date\n",
    "df_sp=df_sp.sort_values(by=\"Date\")\n",
    "df_sp\n",
    "\n",
    "# set index\n",
    "df_sp=df_sp.set_index(\"Date\")\n",
    "df_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out first and last week\n",
    "#df_sp=df_sp.loc[\"2019-03-03\":\"2020-06-28\"]\n",
    "df_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show weekly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp2=df_sp.groupby(\"Week\").agg(\"mean\")\n",
    "df_sp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_mean_percentiles_trans[:\"29.06.2020\"].plot(figsize=(12,8),rot=60)\n",
    "#colourWheel =['#00008b','#a6e9ff']\n",
    "colourWheel =['#00008b','#000000']\n",
    "\n",
    "#plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "ax2 = ax.twinx()  # set up the 2nd axis\n",
    "\n",
    "alphaVal = 1\n",
    "linethick=2\n",
    "\n",
    "ax2.bar(df_weekly_avg_sent_2.index,\n",
    "        df_weekly_avg_sent_2.sum_News_vol,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2, \n",
    "        width=5,\n",
    "        #color=\"blue\",\n",
    "        label=\"News Vol.\",\n",
    "        #alpha=alphaVal\n",
    "       )\n",
    "\n",
    "lns1=ax.plot(df_weekly_avg_sent_2.index,\n",
    "        df_weekly_avg_sent_2.mean_Sent_avg_conf,\n",
    "        color=\"#00008b\",\n",
    "        #color=\"blue\",\n",
    "        linestyle = '-',\n",
    "        #dashes=dashesStyles[j%len(dashesStyles)],\n",
    "        lw=linethick,\n",
    "        label=\"Average Sentiment\",\n",
    "   \n",
    "       # alpha=alphaVal\n",
    "       )\n",
    "\n",
    "ax3 = ax.twinx() \n",
    "\n",
    "lns2=ax3.plot(df_sp2.index,\n",
    "        df_sp2[\".SPX\"],\n",
    "        color=\"green\",\n",
    "        #color=\"blue\",\n",
    "        linestyle = '-',\n",
    "         alpha=.7,\n",
    "        #dashes=dashesStyles[j%len(dashesStyles)],\n",
    "        lw=linethick,\n",
    "        label=\"S&P 500 Index\",\n",
    "       # alpha=alphaVal\n",
    "       )\n",
    "# hide axis three\n",
    "ax3.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "\"\"\"ax.plot(df_weekly_avg_sent_2.index,\n",
    "        df_weekly_avg_sent_2.mean_Sent_conf_neg,\n",
    "        color=\"#000000\",\n",
    "        #color=\"blue\",\n",
    "        linestyle = '-',\n",
    "        #dashes=dashesStyles[j%len(dashesStyles)],\n",
    "        lw=linethick,\n",
    "        label=series,\n",
    "        alpha=alphaVal)\n",
    "\n",
    "ax.plot(df_weekly_avg_sent_2.index,\n",
    "        df_weekly_avg_sent_2.mean_Sent_conf_pos,\n",
    "        color=\"#00000b\",\n",
    "        #color=\"blue\",\n",
    "        linestyle = '-',\n",
    "        #dashes=dashesStyles[j%len(dashesStyles)],\n",
    "        lw=linethick,\n",
    "        label=series,\n",
    "        alpha=alphaVal)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "#df_weekly_avg_sent_2.sum_News_vol.plot(secondary_y=True)\n",
    "\n",
    "ax.set_xlabel('')\n",
    "#ax.yaxis.set_major_formatter(ScalarFormatter())\n",
    "#ax.yaxis.major.formatter._useMathText = True\n",
    "#ax.yaxis.set_minor_locator(  AutoMinorLocator(5))\n",
    "#ax.xaxis.set_minor_locator(  AutoMinorLocator(5))\n",
    "#ax.yaxis.set_label_coords(0.63,1.01)\n",
    "#ax.yaxis.tick_right()\n",
    "\n",
    "#fig.autofmt_xdate()\n",
    "\n",
    "#nameOfPlot = 'GDP per hour (constant prices, indexed to 2007)'\n",
    "ax.set_xlabel(\"Month\",rotation=0)\n",
    "#plt.ylabel(\"Average Sentiment Confidence\",rotation=90)\n",
    "ax.set_ylabel('Average Sentiment Confidence')\n",
    "ax2.set_ylabel('Number of News Headlines')\n",
    "\n",
    "# Set number format for second y axis\n",
    "ax2.get_yaxis().set_major_formatter(\n",
    "mpl.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "# insert legend\n",
    "#ax.legend(frameon=True, title=\"Legend\",loc='lower left',ncol=2,handlelength=2)\n",
    "#plt.legend(loc='lower left')\n",
    "#fig.legend(loc=\"lower left\")\n",
    "lns = lns1+lns2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax.legend(lns, labs, frameon=False,\n",
    "          #title=\"Legend\",\\\n",
    "          loc='lower left',ncol=1,handlelength=1,framealpha=1,facecolor=\"w\")\n",
    "\n",
    "# store to image\n",
    "plt.savefig('Average Sentiment and News Vol. and SP Index by week.png',dpi=300, transparent=False, bbox_inches='tight')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show average negative sentiment per day\n",
    "df_daily_avg_sent=pd.pivot_table(df_sp500_scores_vis,index=[\"Date\"],\\\n",
    "               values=[\"Sent_neg_filt\"],\\\n",
    "               #values=[\"Sent_neg\"],\\\n",
    "               #values=[\"Sent_neg_filt\",\"Sent_neg\"],\\\n",
    "               aggfunc=[np.mean],fill_value=np.NaN)\n",
    "\n",
    "df_daily_avg_sent.plot(figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show average negative sentiment per day\n",
    "df_daily_avg_sent=pd.pivot_table(df_sp500_scores_vis,index=[\"Week\"],\\\n",
    "               values=[\"Sent_avg_conf\"],\\\n",
    "              # values=[\"Sent_avg\"],\\\n",
    "               #values=[\"Sent_neg_filt\",\"Sent_neg\"],\\\n",
    "               aggfunc=[np.mean],fill_value=np.NaN)\n",
    "\n",
    "df_daily_avg_sent.plot(figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show average negative sentiment per day\n",
    "df_daily_avg_sent=pd.pivot_table(df_sp500_scores_vis,index=[\"Date\"],\\\n",
    "               values=[\"Sent_conf_neg\"],\\\n",
    "               #values=[\"Sent_neg\"],\\\n",
    "               #values=[\"Sent_neg_filt\",\"Sent_neg\"],\\\n",
    "               aggfunc=[np.mean],fill_value=np.NaN)\n",
    "\n",
    "df_daily_avg_sent.plot(figsize=(15,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot weekly average sentiment by firm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500_scores_vis.sort_values(by=\"Week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show average sentiment per week\n",
    "df_week_avg_sent_by_comp=pd.pivot_table(df_sp500_scores_vis,index=[\"RIC\"],columns=[\"Week\"],\\\n",
    "               #values=[\"Sent_avg\"],\\\n",
    "               #values=[\"Sent_avg_filt\"],\\\n",
    "               values=[\"Sent_avg_conf\"],\\\n",
    "               #values=[\"Sent_conf_neg\"],\\\n",
    "               aggfunc=[np.mean],fill_value=np.NaN)\n",
    "\n",
    "df_week_avg_sent_by_comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten columns\n",
    "level_three = df_week_avg_sent_by_comp.columns.get_level_values(2).astype(str)\n",
    "df_week_avg_sent_by_comp.columns = level_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[1,2,3,4,5,6,7,8,9,10]\n",
    "#labels=[1,2,3]\n",
    "\n",
    "col_list=df_week_avg_sent_by_comp.columns\n",
    "\n",
    "# Calculate percentiles by week and company\n",
    "for i in col_list:\n",
    "    df_week_avg_sent_by_comp[str(i)+\"_percentile\"]=pd.qcut(df_week_avg_sent_by_comp[i].rank(method='first'),\\\n",
    "                                                      10,\n",
    "                                                      #[0,0.33,0.66,1.0],\\\n",
    "                                                      #duplicates=\"drop\",\\\n",
    "                                                      labels=labels\n",
    "                                                     )\n",
    "\n",
    "df_week_avg_sent_by_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_week_avg_sent_by_comp.to_excel(\"Test_avg_sent_score_by_week.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_week_avg_sent_perc=pd.DataFrame()\n",
    "list_dfs=[]\n",
    "\n",
    "for i in col_list:\n",
    "    df_week_avg_sent_perc=df_week_avg_sent_by_comp.groupby(str(i)+'_percentile').mean()[i]\n",
    "    list_dfs.append(df_week_avg_sent_perc)\n",
    "    \n",
    "#list_dfs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# append dataframes\n",
    "df_mean_percentiles = pd.concat(list_dfs,axis=1)\n",
    "\n",
    "df_mean_percentiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mean_percentiles_trans=df_mean_percentiles.transpose()\n",
    "df_mean_percentiles_trans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter out first and last week\n",
    "df_mean_percentiles_trans=df_mean_percentiles_trans.loc[\"2019-03-03\":\"2020-06-28\"]\n",
    "df_mean_percentiles_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_percentiles_trans.to_excel(\"Weekly_average_Sent_conf by Percentile.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df_mean_percentiles_trans[:\"29.06.2020\"].plot(figsize=(12,8),rot=60)\n",
    "#colourWheel =['#00008b','#a6e9ff']\n",
    "colourWheel =['#00008b','#000000']\n",
    "\n",
    "#plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "for j,series in enumerate(df_mean_percentiles_trans):\n",
    "    if(series==1 or series==10):\n",
    "        alphaVal = 1\n",
    "        linethick=3\n",
    "        ax.plot(df_mean_percentiles_trans[series].index,\n",
    "                df_mean_percentiles_trans[series],\n",
    "                color=colourWheel[j%len(colourWheel)],\n",
    "                #color=\"blue\",\n",
    "                linestyle = '-',\n",
    "                #dashes=dashesStyles[j%len(dashesStyles)],\n",
    "                lw=linethick,\n",
    "                label=series,\n",
    "                alpha=alphaVal)\n",
    "    else:\n",
    "        alphaVal = 0.6\n",
    "        linethick = 1.5\n",
    "        ax.plot(df_mean_percentiles_trans[series].index,\n",
    "                df_mean_percentiles_trans[series],\n",
    "                #color=colourWheel[j%len(colourWheel)],\n",
    "                color=\"grey\",\n",
    "                linestyle = '-',\n",
    "                #dashes=dashesStyles[j%len(dashesStyles)],\n",
    "                lw=linethick,\n",
    "                label=series,\n",
    "                alpha=alphaVal)\n",
    "#ax.set_xlabel('')\n",
    "#ax.yaxis.set_major_formatter(ScalarFormatter())\n",
    "#ax.yaxis.major.formatter._useMathText = True\n",
    "#ax.yaxis.set_minor_locator(  AutoMinorLocator(5))\n",
    "#ax.xaxis.set_minor_locator(  AutoMinorLocator(5))\n",
    "#ax.yaxis.set_label_coords(0.63,1.01)\n",
    "#ax.yaxis.tick_right()\n",
    "plt.xticks(rotation=90)\n",
    "#fig.autofmt_xdate()\n",
    "\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "#loc = plticker.MultipleLocator(base=5.0) # this locator puts ticks at regular intervals\n",
    "#ax.xaxis.set_major_locator(loc)\n",
    "\n",
    "# Hide the top and right spines of the axis\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "#nameOfPlot = 'GDP per hour (constant prices, indexed to 2007)'\n",
    "#plt.xlabel(\"First Day of Week\",rotation=0)\n",
    "plt.ylabel(\"Average Sentiment Confidence\",rotation=90)\n",
    "ax.legend(frameon=False, title=\"Decil\",loc='lower center',ncol=10,handlelength=1)\n",
    "\n",
    "# store to image\n",
    "plt.savefig('Average Sentiment by decil and week.png',dpi=300, transparent=False, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot monthly average sentiment by percentile and month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show average sentiment per week\n",
    "df_month_avg_sent_by_comp=pd.pivot_table(df_sp500_scores_vis,index=[\"RIC\"],columns=[\"Month\"],\\\n",
    "               #values=[\"Sent_avg\"],\\\n",
    "               #values=[\"Sent_avg_filt\"],\\\n",
    "               values=[\"Sent_avg_conf\"],\\\n",
    "               #values=[\"Sent_conf_neg\"],\\\n",
    "               aggfunc=[np.mean],fill_value=np.NaN)\n",
    "\n",
    "# flatten columns\n",
    "level_three = df_month_avg_sent_by_comp.columns.get_level_values(2).astype(str)\n",
    "df_month_avg_sent_by_comp.columns = level_three\n",
    "\n",
    "df_month_avg_sent_by_comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "col_list=df_month_avg_sent_by_comp.columns\n",
    "\n",
    "# Calculate percentiles by week and company\n",
    "for i in col_list:\n",
    "    df_month_avg_sent_by_comp[str(i)+\"_decil\"]=pd.qcut(df_month_avg_sent_by_comp[i].rank(method='first'),10,\\\n",
    "                                                      #duplicates=\"drop\",\\\n",
    "                                                      labels=labels)\n",
    "\n",
    "df_month_avg_sent_by_comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month_avg_sent_perc=pd.DataFrame()\n",
    "list_dfs=[]\n",
    "\n",
    "for i in col_list:\n",
    "    df_month_avg_sent_perc=df_month_avg_sent_by_comp.groupby(str(i)+'_decil').mean()[i]\n",
    "    list_dfs.append(df_month_avg_sent_perc)\n",
    "    \n",
    "#list_dfs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append dataframes\n",
    "df_mean_percentiles = pd.concat(list_dfs,axis=1)\n",
    "\n",
    "df_mean_percentiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_percentiles_trans=df_mean_percentiles.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_mean_percentiles_trans[:\"29.06.2020\"].plot(figsize=(12,8),rot=60)\n",
    "#colourWheel =['#00008b','#a6e9ff']\n",
    "colourWheel =['#00008b','#000000']\n",
    "\n",
    "#plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "for j,series in enumerate(df_mean_percentiles_trans[:]):\n",
    "    if(series==1 or series==10):\n",
    "        alphaVal = 1\n",
    "        linethick=3\n",
    "        ax.plot(df_mean_percentiles_trans[series].index,\n",
    "                df_mean_percentiles_trans[series],\n",
    "                color=colourWheel[j%len(colourWheel)],\n",
    "                #color=\"blue\",\n",
    "                linestyle = '-',\n",
    "                #dashes=dashesStyles[j%len(dashesStyles)],\n",
    "                lw=linethick,\n",
    "                label=series,\n",
    "                alpha=alphaVal)\n",
    "    else:\n",
    "        alphaVal = 0.6\n",
    "        linethick = 1.5\n",
    "        ax.plot(df_mean_percentiles_trans[series].index,\n",
    "                df_mean_percentiles_trans[series],\n",
    "                #color=colourWheel[j%len(colourWheel)],\n",
    "                color=\"grey\",\n",
    "                linestyle = '-',\n",
    "                #dashes=dashesStyles[j%len(dashesStyles)],\n",
    "                lw=linethick,\n",
    "                label=series,\n",
    "                alpha=alphaVal)\n",
    "ax.set_xlabel('')\n",
    "#ax.yaxis.set_major_formatter(ScalarFormatter())\n",
    "#ax.yaxis.major.formatter._useMathText = True\n",
    "#ax.yaxis.set_minor_locator(  AutoMinorLocator(5))\n",
    "#ax.xaxis.set_minor_locator(  AutoMinorLocator(5))\n",
    "#ax.yaxis.set_label_coords(0.63,1.01)\n",
    "#ax.yaxis.tick_right()\n",
    "plt.xticks(rotation=60)\n",
    "#fig.autofmt_xdate()\n",
    "\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "loc = plticker.MultipleLocator(base=1.0) # this locator puts ticks at regular intervals\n",
    "ax.xaxis.set_major_locator(loc)\n",
    "\n",
    "#nameOfPlot = 'GDP per hour (constant prices, indexed to 2007)'\n",
    "plt.xlabel(\"Year-Month\",rotation=0)\n",
    "plt.ylabel(\"Average Sentiment Confidence\",rotation=90)\n",
    "ax.legend(frameon=False, title=\"Decil\",loc='lower center',ncol=10,handlelength=1)\n",
    "#plt.savefig(os.path.join(dirFile,'test.png'),dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show average negative sentiment per day\n",
    "df_daily_avg_sent=pd.pivot_table(df_sp500_scores_vis,index=[\"Date\"],\\\n",
    "               values=[\"Sent_neg_filt\"],\\\n",
    "               #values=[\"Sent_neg\"],\\\n",
    "               #values=[\"Sent_neg_filt\",\"Sent_neg\"],\\\n",
    "               aggfunc=[np.mean],fill_value=np.NaN)\n",
    "\n",
    "df_daily_avg_sent.plot(figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show average negative sentiment per day\n",
    "df_daily_avg_sent=pd.pivot_table(df_sp500_scores_vis,index=[\"Week\"],\\\n",
    "               values=[\"Sent_avg_conf\"],\\\n",
    "              # values=[\"Sent_avg\"],\\\n",
    "               #values=[\"Sent_neg_filt\",\"Sent_neg\"],\\\n",
    "               aggfunc=[np.mean],fill_value=np.NaN)\n",
    "\n",
    "df_daily_avg_sent.plot(figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show volume of news per day\n",
    "df_daily_avg_sent=pd.pivot_table(df_sp500_scores_vis,index=[\"Date\"],\\\n",
    "             values=[\"News_vol\"],\\\n",
    "               #values=[\"Sent_ratio\"],\\\n",
    "              # values=[\"Sent_ratio\",\"Sent_ratio_filt\"],\\\n",
    "               aggfunc=[np.mean],fill_value=np.NaN)\n",
    "\n",
    "#df_daily_avg_sent.plot(kind=\"bar\",figsize=(15,5))\n",
    "df_daily_avg_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse average daily sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load average daily media attention decils\n",
    "df_Quantiles=pd.read_excel(\"RIC and News Quantiles.xlsx\")\n",
    "df_Quantiles=df_Quantiles.drop_duplicates(subset=\"Company\")\n",
    "df_Quantiles=df_Quantiles[[\"Company\",\"News_Quantile\"]]\n",
    "df_Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500_scores_vis.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join percentiles \n",
    "df_sp500_scores_vis_inc_dec=df_sp500_scores_vis.merge(df_Quantiles,how=\"left\",left_on=\"RIC\",right_on=\"Company\")\n",
    "\n",
    "df_sp500_scores_vis_inc_dec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show average sentiment stats\n",
    "df_sp500_scores_vis_inc_dec_piv=pd.pivot_table(df_sp500_scores_vis_inc_dec,index=[\"News_Quantile\"],\\\n",
    "               values=[\"Sent_avg_conf\"],\\\n",
    "               aggfunc=[np.mean, \"median\",\"max\",\"std\",\"skew\"],fill_value=np.NaN)\n",
    "df_sp500_scores_vis_inc_dec_piv.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500_scores_vis_inc_dec_piv.to_excel(\"Average daily sentiment by decil of media coverage.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load industries\n",
    "df_Industry=pd.read_excel(\"RIC and Industry Sector 2.xlsx\")\n",
    "df_Industry=df_Industry.drop_duplicates(subset=\"RIC\")\n",
    "#df_Industry=df_Industry[[\"Company\",\"News_Quantile\"]]\n",
    "df_Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sp500_scores_vis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join industries \n",
    "df_sp500_scores_vis_inc_ind=df_sp500_scores_vis.merge(df_Industry,how=\"left\",left_on=\"RIC\",right_on=\"RIC\")\n",
    "\n",
    "df_sp500_scores_vis_inc_ind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show average sentiment per week\n",
    "df_sp500_scores_vis_inc_ind_piv=pd.pivot_table(df_sp500_scores_vis_inc_ind,index=[\"ICB Sector\"],\\\n",
    "               values=[\"Sent_avg_conf\"],\\\n",
    "               aggfunc=[np.mean, \"median\",\"max\",\"std\",\"skew\"],fill_value=np.NaN)\n",
    "#df_sp500_scores_vis_inc_ind_piv.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500_scores_vis_inc_ind_piv.to_excel(\"Average daily sentiment by industry.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
