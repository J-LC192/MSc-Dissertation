{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headlines Receiver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import eikon as ek\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "import datetime\n",
    "#from datetime import time \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ek.set_app_key('###########') # replace with app key\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Constituents\n",
    "\n",
    "### Thomson Reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dataframe of current S&P 500 Constituents\n",
    "# Source: https://community.developers.refinitiv.com/questions/28646/historical-component-stocks-of-sp-500-index.html\n",
    "#data_SPX= ek.get_data(['.SPX'], ['TR.IndexConstituentRIC','TR.IndexConstituentName'])\n",
    "\n",
    "# Get Dataframe of current S&P 100 Constituents\n",
    "#data_OEXA= ek.get_data(['.OEXA'], ['TR.IndexConstituentRIC','TR.IndexConstituentName'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tuple to dataframe\n",
    "#df_SPX =  pd.DataFrame(data_SPX, columns =['Instrument', 'Constituent RIC', 'Constituent Name'])\n",
    "#df_SPX =  pd.DataFrame(data_SPX[0],columns =['Instrument', 'Constituent RIC', 'Constituent Name'])\n",
    "#df_SPX[:]\n",
    "\n",
    "#df_OEXA =  pd.DataFrame(data_OEXA[0],columns =['Instrument', 'Constituent RIC', 'Constituent Name'])\n",
    "#df_OEXA[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store dataframe to excel\n",
    "#df_SPX.to_excel(\"SPX_Constituents.xlsx\")\n",
    "#df_OEXA.to_excel(\"OEXA_Constituents.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WRDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load WRDS constituents list\n",
    "cols=[\"from\",\"thru\",\"co_conm\",\"co_tic\",\"co_cusip\"]\n",
    "df_SPX_hist=pd.read_excel(\"../../07_WRDS/1_S&P 500 Index constituents/6.1_SPX_Constituents_incl_filled_dates - corr WRDS error.xlsx\",usecols=cols)\n",
    "df_SPX_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dataframes\n",
    "dfs = []  \n",
    "\n",
    "#comp_list=df_SPX_hist.co_cusip.tolist()\n",
    "comp_list=df_SPX_hist.co_cusip.tolist()\n",
    "len(comp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all RICS jointly from list\n",
    "#rics = ek.get_symbology(comp_list,from_symbol_type=\"CUSIP\", to_symbol_type=\"RIC\")\n",
    "#rics\n",
    "\n",
    "for c in comp_list:\n",
    "    r = ek.get_symbology(c,from_symbol_type=\"CUSIP\", to_symbol_type=\"RIC\")\n",
    "    dfs.append(r)\n",
    "\n",
    "rics = pd.concat(dfs)\n",
    "\n",
    "print(rics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add RICS to WRDS list and save to excel\n",
    "df_SPX_hist[\"RIC\"]=rics.RIC.to_list()\n",
    "df_SPX_hist.to_excel(\"../WRDS_SPX_constituent incl RICS.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SPX_hist[df_SPX_hist.RIC.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receive News Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter= df_SPX[\"Constituent Name\"].str.contains('APPLE')\n",
    "#df_SPX['Constituent RIC'][filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Get news articles - only receives news from NewsWire\"\"\"\n",
    "# R:IBM.N AND Topic:COVID AND Language:LEN\n",
    "# Receive topics as field\n",
    "#df = ek.get_news_headlines('R:IBM.N AND Language:LEN', date_from = \"2019-06-01\", count=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import manually completed SPX constitutents list\n",
    "df_const=pd.read_excel(\"../../07_WRDS/1_S&P 500 Index constituents/1_WRDS_SPX_constituent incl RICS_manually completed.xlsx\")\n",
    "df_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format date columns\n",
    "df_const[\"from\"]=pd.to_datetime(df_const[\"from\"],format='%Y%m%d').dt.normalize()\n",
    "df_const[\"thru\"]=pd.to_datetime(df_const[\"thru\"],format='%Y%m%d').dt.normalize()\n",
    "df_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up requests\n",
    "from random import random\n",
    "import time\n",
    "\n",
    "# Define start and end date\n",
    "\n",
    "# Set up date variables\n",
    "start_month=10\n",
    "start_year= 2019\n",
    "\n",
    "# Set up date variables\n",
    "end_month=10\n",
    "end_year= 2019\n",
    "\n",
    "\n",
    "fixed_end_date= datetime(end_year, end_month, 15)\n",
    "end_date =fixed_end_date\n",
    "\n",
    "start_date = datetime(start_year, start_month, 15)\n",
    "\n",
    "# replace start date < start date with start date \n",
    "df_const[\"from\"]=[start_date if x < start_date else x for x in df_const[\"from\"]]\n",
    "\n",
    "# replace NaT in thru with end date\n",
    "df_const[\"thru\"]=[fixed_end_date if pd.isnull(x) else x for x in df_const[\"thru\"]]\n",
    "\n",
    "df_const\n",
    "df_const.to_excel(\"Fill_missing_datesSPX_Constituents_incl_dates.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read prepared file\n",
    "df_const=pd.read_excel(\"Fill_missing_news_14-10-19-SPX_Constituents_incl_dates.xlsx\")\n",
    "df_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# format date columns\n",
    "df_const[\"from\"]=pd.to_datetime(df_const[\"from\"],format='%Y%m%d').dt.normalize()\n",
    "df_const[\"thru\"]=pd.to_datetime(df_const[\"thru\"],format='%Y%m%d').dt.normalize()\n",
    "df_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create datestring\n",
    "datestring_time = datetime.strftime(datetime.now(),\"%m_%d_%Y, %H_%M_%S\")\n",
    "\n",
    "#comp_list=['CHRW.OQ','AJG.N','CNP.N','AMCR.N','WM.N']\n",
    "#comp_list=['AAPL.OQ','CHRW.OQ']\n",
    "\n",
    "\n",
    "collect_headlines = []\n",
    "success= False\n",
    "comp_loop_count=0\n",
    "request_loop_count=0\n",
    "\n",
    "\n",
    "# loop through list of companies\n",
    "for index,row in df_const[:].iterrows():\n",
    "    \n",
    "    # set end date to row end date\n",
    "    end_date= row[\"thru\"]\n",
    "    \n",
    "    while success==False:    \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # receive dataframe of news\n",
    "            df = ek.get_news_headlines('R:'+str(row[\"RIC\"])+' AND Language:LEN', \\\n",
    "                                       date_from = str(row[\"from\"]), date_to=str(end_date), count=100)\n",
    "            request_loop_count+=1\n",
    "            time.sleep(random() * 10 * 1)\n",
    "            \n",
    "            # set RIC to retrieved company\n",
    "            df[\"RIC\"]= row[\"RIC\"]\n",
    "            \n",
    "        \n",
    "            # append dataframe to list of dataframes\n",
    "            collect_headlines.append(df)\n",
    "            \n",
    "            # if empty dataframe is received or end date = last date of retrieved dataframe\n",
    "            if (df.shape[0]==0) or (end_date == df.tail(1).index.item()):\n",
    "                success=True\n",
    "            else:\n",
    "                # set index of last retrieved data as end date\n",
    "                end_date = df.tail(1).index.item()\n",
    "            \n",
    "        except Exception as exc:\n",
    "                print(f\"Encountered an unknown error: {exc}\")\n",
    "                \n",
    "                # set RIC to retrieved company\n",
    "                df[\"RIC\"]= row[\"RIC\"]\n",
    "                \n",
    "                # append dataframe to list of dataframes\n",
    "                collect_headlines.append(df)\n",
    "                \n",
    "                # concat all dataframes into one\n",
    "                df_headlines = pd.concat(collect_headlines)\n",
    "                \n",
    "                # store in csv\n",
    "                df_headlines.to_csv(str(start_date.date())+ \"_to_\" + str(end_date.date()) + \"_time_\"+ datestring_time + \"_headlines.csv\")\n",
    "                print(\"Last RIC: \"+ str(row[\"RIC\"]) +\" Last enddate: \"+str(end_date)+ \" Error at: \"+str(datetime.now()))\n",
    "                raise\n",
    "        \n",
    "    # reset end date and success\n",
    "    #end_date=fixed_end_date   \n",
    "    success=False\n",
    "    \n",
    "    # Count iterations\n",
    "    comp_loop_count+=1\n",
    "    print(f\"Done with: number: {index},total loops: {request_loop_count}\")\n",
    "\n",
    "# concat all dataframes into one\n",
    "df_headlines = pd.concat(collect_headlines)\n",
    "\n",
    "# store in csv\n",
    "df_headlines.to_csv(str(start_date.date())+ \"_to_\"+ str(fixed_end_date.date())+ \"_time_\" + datestring_time + \"_headlines.csv\")\n",
    "print(f\"Done, requests sent: {request_loop_count} time: {datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
