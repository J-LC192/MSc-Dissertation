{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting and filtering received headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Headline files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import datetime\n",
    "from datetime import time\n",
    "\n",
    "\n",
    "#path = r'C:\\DRO\\DCL_rawdata_files' # use your path\n",
    "path = '' # use your path\n",
    "all_files = glob.glob(\"4_WRDS_SP 500 Headlines completed/Single Files/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "# Load all files\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert versionCreated to datetime\n",
    "frame.versionCreated =pd.to_datetime(frame.versionCreated)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to version created without timestamp\n",
    "frame.set_index(frame['versionCreated'].dt.normalize(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original 'index' timestamp\n",
    "frame.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(frame[\"RIC\"]==\"APA.O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change APA.0 to APA (fix that a different Ticker was used for same company)\n",
    "frame[\"RIC\"].replace({\"APA.O\": \"APA\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(frame[\"RIC\"]==\"APA.O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by index\n",
    "frame = frame.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "frame= frame.drop_duplicates()\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[frame.sourceCode== \"NS:EDG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[frame.sourceCode== \"NS:GLFILE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[frame.sourceCode== \"NS:TRANS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out specific news sources\n",
    "frame=frame[frame.sourceCode!= \"NS:EDG\"]\n",
    "frame=frame[frame.sourceCode!= \"NS:TRANS\"]\n",
    "frame=frame[frame.sourceCode!= \"NS:GLFILE\"]\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove headlines with wrong tagging of CBOE.K unitl end of June 2019\n",
    "frame[((frame.sourceCode== \"NS:PUBT\") & (frame.RIC==\"CBOE.K\") & (frame.index<\"2020-06-30\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove headlines with wrong tagging of CBOE.K unitl end of June 2019\n",
    "frame=frame[~((frame.sourceCode== \"NS:PUBT\") & (frame.RIC==\"CBOE.K\") & (frame.index<\"2020-06-30\"))]\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[frame.RIC== \"MCO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove headlines for Moodys\n",
    "frame=frame[frame.RIC!= \"MCO\"]\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out February / July news\n",
    "frame=frame.loc['2019-03-01':'2020-06-30']\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store frame into dataframe\n",
    "frame.to_csv(\"4_WRDS_SP 500 Headlines completed/2019_03_01_to_2020_06_30_Headlines_SP500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create flag column that concatenates text, sourcecode and RIC\n",
    "frame[\"Duplicate_Flag\"]= (frame.text+frame.sourceCode+frame.RIC).str.lower()\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find day with duplicates headlines\n",
    "frame.loc[\"2020-06-01\"].sort_values(\"text\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename index label\n",
    "frame.index.rename('versionCreated.1',inplace=True)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by version created\n",
    "frame = frame.sort_values(by=frame.columns[0])\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frame.drop_duplicates(\"Duplicate_Flag\",inplace=True)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again day with duplicates headlines\n",
    "frame.loc[\"2020-06-01\"].sort_values(\"text\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frame=frame.drop(\"Duplicate_Flag\",axis=1)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many news are on weekends\n",
    "import holidays\n",
    "\n",
    "us_holidays = holidays.UnitedStates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "# As the expand parameter of uk_holidays= True, the list of holidays will expand\n",
    "# for each year that is checked. Therfore, we generate a loop to effectivley initialise all \n",
    "# holidays from 2000- 2020 in the holiday object\n",
    "for x in range (2019,2020):\n",
    "  date(x, 1, 1) in us_holidays\n",
    "\n",
    "# Check length of holiday object\n",
    "len(us_holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[\"Holiday_Flag\"]=frame.index.isin(us_holidays)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[frame.Holiday_Flag==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out holidays\n",
    "frame=frame[frame.Holiday_Flag==False]\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_days={0:\"Mon\",\n",
    "          1:\"Tue\",\n",
    "          2:\"Wed\",\n",
    "          3:\"Thu\",\n",
    "          4:\"Fri\",\n",
    "          5:\"Sat\",\n",
    "          6:\"Sun\"}\n",
    "\n",
    "\n",
    "# Insert controll variable for the day of the week (0=Monday, 6=Sunday)\n",
    "frame[\"Weekday\"]=pd.to_datetime(frame.index).dayofweek.map(dict_days)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[frame.Weekday.isin([\"Sat\",\"Sun\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=frame[~frame.Weekday.isin([\"Sat\",\"Sun\"])]\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=frame.drop(columns=[\"Holiday_Flag\",\"Weekday\"])\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(662739-8772)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store frame into dataframe\n",
    "frame.to_csv(\"4_WRDS_SP 500 Headlines completed/2019_03_01_to_2020_06_30_Headlines_SP500_filt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of news headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frame[\"storyId\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique news\n",
    "frame[\"storyId\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe containing unique storyIds\n",
    "news_Ids=frame[[\"storyId\",\"sourceCode\"]]\n",
    "print(news_Ids.shape)\n",
    "news_Ids=news_Ids.drop_duplicates()\n",
    "print(news_Ids.shape)\n",
    "\n",
    "# Store dataframe containing only unique headlines\n",
    "news_Ids.to_csv(\"4_WRDS_SP 500 Headlines completed/2019_03_01_to_2020_04_30_unique_HeadlineIds_SP100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rough monthly estimate\n",
    "frame[\"storyId\"].nunique()/13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print latest news date\n",
    "max(frame.versionCreated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average news frequency per company per day\n",
    "frame[\"storyId\"].nunique()/505/370"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[\"month_year\"]=frame.versionCreated.dt.strftime('%Y-%m')\n",
    "frame[\"month_year_day\"]=frame.versionCreated.dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "\n",
    "# Generate pivot table of sum of news per day per company\n",
    "piv_table_news = pd.pivot_table(frame,index=['RIC'],columns=[frame.month_year],\\\n",
    "               values=[\"storyId\"],\\\n",
    "               aggfunc=['count'],fill_value=0)\n",
    "\n",
    "# Display the table\n",
    "piv_table_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in excel\n",
    "piv_table_news.to_excel(\"4_WRDS_SP 500 Headlines completed/Overview News per Company and month.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis Daily averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis daily averages\n",
    "\n",
    "# Generate pivot table of sum of news per day per company\n",
    "piv_table_news_daily = pd.pivot_table(frame,index=['RIC'],columns=[frame.month_year_day],\\\n",
    "               values=[\"storyId\"],\\\n",
    "               aggfunc=['count'],fill_value=0)\n",
    "\n",
    "# Display the table\n",
    "piv_table_news_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv_table_news_daily[piv_table_news_daily.index==\"CBOE.K\"].to_excel(\"check_CBOE.K_new_vol.xlsx\")\n",
    "piv_table_news[piv_table_news.index==\"CBOE.K\"].to_excel(\"check_CBOE.K_new_vol_monthly.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[frame.RIC==\"CBOE.K\"].reset_index()[[\"month_year_day\",\"text\",\"sourceCode\",\"RIC\"]].to_excel(\"CBOE.K News.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check only news for PUBT \n",
    "frame[frame.sourceCode==\"NS:PUBT\"].reset_index()[[\"month_year_day\",\"text\",\"sourceCode\",\"RIC\"]].to_excel(\"PUBT News.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv_table_news_daily_sum= pd.DataFrame()\n",
    "piv_table_news_daily_sum[\"Mean\"]=piv_table_news_daily.mean(axis=1)\n",
    "piv_table_news_daily_sum[\"Median\"]=piv_table_news_daily.median(axis=1)\n",
    "piv_table_news_daily_sum[\"Max\"]=piv_table_news_daily.max(axis=1)\n",
    "piv_table_news_daily_sum[\"Count_days\"]=piv_table_news_daily.count(axis=1)\n",
    "piv_table_news_daily_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate days with no articles\n",
    "piv_table_news_daily_sum[\"days_with_no_articles\"]=(piv_table_news_daily == 0).sum(axis=1)\n",
    "piv_table_news_daily_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate % of days with no articles\n",
    "piv_table_news_daily_sum[\"days_with_no_articles_PERC\"]=piv_table_news_daily_sum[\"days_with_no_articles\"]/piv_table_news_daily_sum[\"Count_days\"]\n",
    "piv_table_news_daily_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in excel\n",
    "piv_table_news_daily_sum.to_excel(\"4_WRDS_SP 500 Headlines completed/Overview News count per Company and day.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis by Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[\"month_year\"]=frame.versionCreated.dt.strftime('%Y-%m')\n",
    "\n",
    "# Generate pivot table of sum news per author\n",
    "piv_table_authors = pd.pivot_table(frame,index=['sourceCode'],columns=[frame.month_year],\\\n",
    "               values=[\"storyId\"],\\\n",
    "               aggfunc=['count'],fill_value=0)\n",
    "\n",
    "# Display the table\n",
    "piv_table_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in excel\n",
    "piv_table_authors.to_excel(\"4_WRDS_SP 500 Headlines completed/Overview News per Author and month.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many news are on weekends\n",
    "import holidays\n",
    "\n",
    "us_holidays = holidays.UnitedStates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "# As the expand parameter of uk_holidays= True, the list of holidays will expand\n",
    "# for each year that is checked. Therfore, we generate a loop to effectivley initialise all \n",
    "# holidays from 2000- 2020 in the holiday object\n",
    "for x in range (2019,2020):\n",
    "  date(x, 1, 1) in us_holidays\n",
    "\n",
    "# Check length of holiday object\n",
    "len(us_holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[\"Holiday_Flag\"]=frame.index.isin(us_holidays)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.loc[\"2019-05-27\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frame[frame.Holiday_Flag==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ptr in holidays.UnitedStates(years = 2019).items(): \n",
    "    print(ptr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5,177 news on holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_days={0:\"Mon\",\n",
    "          1:\"Tue\",\n",
    "          2:\"Wed\",\n",
    "          3:\"Thu\",\n",
    "          4:\"Fri\",\n",
    "          5:\"Sat\",\n",
    "          6:\"Sun\"}\n",
    "\n",
    "\n",
    "# Insert controll variable for the day of the week (0=Monday, 6=Sunday)\n",
    "frame[\"Weekday\"]=pd.to_datetime(frame.index).dayofweek.map(dict_days)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[frame.Weekday.isin([\"Sat\",\"Sun\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34,123 news are on weekends.\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "Holliday and Weekend news account for\n",
    "\n",
    "34,123 + 5,177 = 39,300 news\n",
    "\n",
    "of 702,039 news articles\n",
    "\n",
    "39300/702039= 0,5597 = 5.6% of all news"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
